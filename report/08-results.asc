== Experimental results

At this point it is time to see how our algorithm scales over multiple concurrent threads and if the use of
vectorized instructions allows us to gain the huge speedup we predicted. We start by graphing the performance over an
SXGA 1280x1024 image and a 8K image, and further scaling up to 24 cores on Google Compute Engine.

[width="80%", align="center"]
vegalite::vega/bench_6900.json[]

[width="80%", align="center"]
vegalite::vega/bench_6900_8k.json[]

[width="80%", align="center"]
vegalite::vega/bench_cloud.json[]

Using regular kernels both on an Intel Core i7-6900k and an (unknown) Xeon provisoned by Google Compute Engine, we can
observe an effective speedup of ~2.0 each time we double the number of cores used. However, this does not hold true when
we exceed the number of physical cores â€” _Hyper-Threading_ works only when we have stalls in one of the two threads
of a physical core, while in our case the cores always have 100% utilization; in fact the performance gain obtained by
using all the _virtual_ cores is minimal.

It can be observed that the measured Xeon processor is very likely at least a 12-core CPU with Hyper-Threading too,
and that running our algorithm with 16 threads (using all the physical cores and then some "virtual" cores) we have
worse results than using only the 12 physical cores.

[width="80%", align="center"]
vegalite::vega/bench_6900_simd.json[]

[width="80%", align="center"]
vegalite::vega/bench_6900_simd_8k.json[]

Regarding SIMD, we have (using an 8K image) an effective speeedup of 15.36 for SSE2 (theoretical 16.00) and of 25.9
for AVX2 (th. 32.00), single thread.

We also found out that by using smaller images, the gain obtained by using AVX2 with respect to SSE2 is not so
noticeable.

NOTE: Using vector instructions we achieved processing times less than 40ms for HD images, meaning that we can
process >25fps HD video in real time.

[width="80%", align="center"]
vegalite::vega/bench_cloud_simd.json[]

On the cloud instance, other than testing also AVX512, we can still see that using 12 threads is a better choice than
going with 16 for the reason explained above.

=== Comparing compilers

Another interesting experiment may be to measure the performance of the binary produced by different toolchains.
GCC and LLVM Clang are free and open source compilers available for all major platforms, while Microsoft's optimizing
compiler `cl` is part of the Visual Studio toolchain.

All binaries were compiled in release mode optimized for maximum speed (`-O3` in GCC and Clang, `/O2` for cl).
All the tools were at their latest version at the time of this writing.

[width="80%", align="center"]
vegalite::vega/bench_compilers.json[]

[width="80%", align="center"]
vegalite::vega/bench_compilers_simd.json[]

It is interesting to note that Clang performs slightly better than GCC with no use of SIMD instructions, while GCC
outperforms it when SIMD is on. The trend remains with smaller images, where Clang's speedup in non-SIMD kernels
becomes more noticeable.

Even after additional research we weren't able to get any faster build from MSVC.

NOTE: MSVC's ABI is not compatible with GCC and Clang, dependencies like OpenCV need to be re-compiled for each ABI.

