== SIMD with Intel intrinsics

In the search for an additional gain in performance, we directed our research towards processor instruction set
extensions for x86, in particular the SIMD instructions offered by MMX, SSE and AVX.

A modern compiler would ideally emit these instructions in an optimized build, however we were not able to observe
changes in performance by toggling on and off SIMD support by the compiler after various attempts of reorganization of
our code.

=== Choosing instruction sets

While SSE and AVX introduced packed floating-point operations, SSE2 and AVX2 allow for (non-)saturated integer
arithmetic. We decided to implement support for SSE2, AVX2 and AVX512, each capable of operating over respectively,
16, 32 and 64 packed 8-bit grayscale pixels in a single operation.

MMX was not considered since it does not support the _max_ and _min_ operations we needed; we thought the overhead
of packing/unpacking the pixels from the registers to be excessive considering the availability of the more powerful
SSE2 since Pentium 4 in 2000.

AVX512F/AVX512BW is mainly available on Intel's Xeon line of server processors and can be tested on the hosts provided by the
Google Cloud Platform.

=== Using instrinsics

An extensive guide to available intrinsics can be consulted on
https://software.intel.com/sites/landingpage/IntrinsicsGuide/[Intel's website]. Call to intrinsic functions are
substituted by their equivalent instruction at compile time, arguments to the function are parameters for the
instruction and are typed accordingly. The effective assignment of the registers is again a task of the compiler.

Translated in terms of our project, we can use CMake options to force-enable support for an instruction set by
the compiler and declare preprocessor defines to conditionally compile and use SIMD kernels.

.kernels.h
[source,c++]
----
// [...]

namespace morph {
    namespace kern {

        // [...]

#ifdef MORPH_ENABLE_SIMD_SSE2
#include "simddefs.sse2.inl"

        KERN_METHOD_DEF(sse2);

        KERN_METHOD(Dilate, sse2) {
#define K_METHOD_DILATE
#include "kern_sched_cpu.inl"
        }

        KERN_METHOD(Erode, sse2) {
#define K_METHOD_ERODE
#include "kern_sched_cpu.inl"
        }

#include "simddefs_clear.inl"
#endif

        // [...]

    }
}
----

By renaming the intrinsics inside `simddefs.*.inl`, we can abstract the kernel from the effective type of SIMD
extension in use.

.simddefs.avx512.inl
[source,c++]
----
#define SIMD_WIDTH 64   // 512b
#define simdi_t    __m512i

// 8-bit unsigned arithmetic, saturated
#define simd_adds_epu8  _mm512_adds_epu8
#define simd_subs_epu8  _mm512_subs_epu8

// 8-bit unsigned comparison
#define simd_max_epu8   _mm512_max_epu8
#define simd_min_epu8   _mm512_min_epu8

// 8-bit set1 broadcast
#define simd_set1_epi8  _mm512_set1_epi8

// 512 bit data load/store
#define simd_loadu      _mm512_loadu_si512
#define simd_storeu     _mm512_storeu_si512
----

With this we only need to take care of generating a plan with chunks of the width of the instruction set being used.

Support for an instruction set is defined at compile time while at runtime the code performs a `cpuid` to pick the best
instruction set available. This selection can be overridden by the use of environment variables.

=== Results

// TODO
//Where needed, parallelization of these algorithms combined with the use of the right CPU features allows to achieve
//real-time HD video processing in less than 25ms.
