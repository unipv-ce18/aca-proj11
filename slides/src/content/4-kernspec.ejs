<div id="kern1" class="step" data-x="1000" data-scale="2" data-rotate-z="90">
    <p>
        The planning code provides us an array, which is then used by the operator template executor:
    </p>
    <ul>
        <li><i>The outer array</i> is indexed by <code>omp_get_thread_num()</code>;</li>
        <li><i>The inner one</i> is iterated in each thread and contains the chunks to work on.</li>
    </ul>
    <p>
        Each chunk has a type and is used to select the kernel better suited to process it
    </p>
    <div class="additional-content">
        <h4>process_parallel.cpp</h4>
        <pre class="hljs cpp"><code>template&lt;typename Operator, typename OpArgs = typename KernelParams&lt;Operator&gt;::type>
void processParallel(parallel::Plan &amp;plan, OpArgs &amp;params) {    (1)
    const auto &alloc = plan.effectiveRegions().allocation();

    using namespace morph::kern;

#pragma omp parallel default(none) shared(alloc, params) num_threads(alloc.size())
    {
        int core = omp_get_thread_num();

        for (const auto &ch : alloc[core]) {
            switch (ch.type) {                                  (2)
                case CHUNK_REGULAR:
                    // Use regular non-checking kernel here
                    _kernel_single&lt;Operator&gt;(params, ch);
                    break;
                default:
                    // Use "safe" kernel for image borders
                    _kernel_single_safe&lt;Operator&gt;(params, ch);
                    break;
            }
        }
    }
}</code></pre>
    </div>

    <div class="notes">
        <ul class="notes-luca">
            <li>Outer idx by thread, inner iter chunks</li>
            <li><b>Show process_parallel.cpp</b> (fast)</li>
            <li>Select best kernel by type</li>
            <li>Why template function</li>
        </ul>
    </div>
</div>

<div id="kern2" class="step" data-x="0" data-scale="2" data-rotate-z="90">
   <p>
       To avoid code duplication, all kernels are variants of a single inline file, which is parameterized by the
       preprocessor and included multiple times in <code>kernels.h</code>.
   </p>
    <p>
        Each operator has kernel variants for the edges and the main part of the image,
        for which we skip any branch for border checking.
    </p>
    <blockquote>
        Kernels are <code>inline</code> to avoid the overhead of function calls whenever possible,<br>
        at the cost of binary file size.
    </blockquote>
    <div class="additional-content">
        <h4>kernels.h</h4>
        <pre class="hljs cpp"><code>#define KERN_METHOD_DEF(var) \
    template&lt;typename Operator&gt; \
    inline void _kernel_##var(typename KernelParams&lt;Operator&gt;::type &args, const parallel::Chunk &ch)

#define KERN_METHOD(op, var) \
    template&lt;&gt; inline void _kernel_##var&lt;op&gt;(typename KernelParams&lt;op&gt;::type &args, const parallel::Chunk &ch)

namespace morph {
    namespace kern {

        // Non-SIMD (single-pixel) kernels
        KERN_METHOD_DEF(single);                (1)

        // "safe" kernels with border checks
        KERN_METHOD_DEF(single_safe);

        KERN_METHOD(Dilate, single) {
#define K_METHOD_DILATE
#include "kern_sched_cpu.inl"
        }

        KERN_METHOD(Dilate, single_safe) {
#define K_METHOD_DILATE                         (2)
#define K_ENABLE_BORDER_CHECKS
#include "kern_sched_cpu.inl"
        }

        KERN_METHOD(Erode, single) {
#define K_METHOD_ERODE
#include "kern_sched_cpu.inl"
        }

        KERN_METHOD(Erode, single_safe) {
#define K_METHOD_ERODE
#define K_ENABLE_BORDER_CHECKS
#include "kern_sched_cpu.inl"
        }

    }
}</code></pre>
    </div>

    <div class="notes">
        <ul class="notes-luca">
            <li>Single include to avoid duplication</li>
            <li>Variants by operator, by chunk type</li>
            <li>Select best kernel by type</li>
            <li><b>Show kernels.h</b> (fast)</li>
            <li>Why inline functions and template</li>
        </ul>
    </div>
</div>

<div id="custresults" class="step" data-x="500" data-y="3000" data-z="0" data-scale="2" data-rotate-x="-20">
    <h2>Performance impact of custom planning</h2>
    <img src=<%=require(REPORT_IMAGES_DIR + 'bench_comp_plan.svg')%>>
    <img src=<%=require(REPORT_IMAGES_DIR + 'bench_comp_plan_8k.svg')%>>
    <p>
        With custom planning and kernels we managed to achieve a speedup up to ~1.17;
        further optimization become possible <span class="yellow">as shown in yellow</span>.
    </p>

    <div class="notes">
        <ul class="notes-domk">
            <li>Check of effective speedup of our algorithm</li>
            <li>Better with bigger images</li>
            <li>Better after VTune optimization <i>only possible on our specialized kernels</i></li>
        </ul>
    </div>
</div>
